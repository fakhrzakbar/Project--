{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMzRKXF2YUU8OBEzvx+PHYS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fakhrzakbar/Project--/blob/main/analysis_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Performance and Aptitude Analysis\n",
        "# The Key English Course Company - Indonesia\n",
        "\n",
        "### A Comprehensive Data-Driven Study\n",
        "\n",
        "**Analysis Date:** January 13, 2026\n",
        "**Total Students:** 150 (50 per course level)\n",
        "**Variables Analyzed:** Performance Scores, Aptitude Scores\n",
        "**Statistical Methods:** ANOVA, Correlation, Effect Sizes, Post-Hoc Tests#\n"
      ],
      "metadata": {
        "id": "VllDSTbAWoub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1: Environment Setup"
      ],
      "metadata": {
        "id": "sYdnrDxqXpTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
      ],
      "metadata": {
        "id": "VuHqBUX5IMq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2: Data Loading and Overview"
      ],
      "metadata": {
        "id": "hXiPFlxyZG4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('student_combined_data.csv')\n",
        "print(\"Combined Data Shape:\", df.shape)\n",
        "display(df.head())\n",
        "print(\"\\nData Info:\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "fS0xGCpzXwPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Descriptive Statistics by Course Level"
      ],
      "metadata": {
        "id": "lN5whn4aZOS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Descriptive Statistics for All Columns (Excluding student_id) ---\")\n",
        "display(df.drop(columns=['student_id']).describe())\n",
        "\n",
        "print(\"\\n--- Performance Score Stats by Course Level ---\")\n",
        "perf_stats = df.groupby(\"course_level\", observed=False)[\"performance_score\"].describe()\n",
        "display(perf_stats)\n",
        "\n",
        "print(\"\\n--- Aptitude Score Stats by Course Level ---\")\n",
        "apt_stats = df.groupby(\"course_level\", observed=False)[\"aptitude_score\"].describe()\n",
        "display(apt_stats)"
      ],
      "metadata": {
        "id": "sxhW4sr1OCbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calculate Basic Statistics ---\n",
        "# We select the two relevant columns and use .agg to get most stats at once\n",
        "overall_stats = df[['performance_score', 'aptitude_score']].agg(['mean', 'median', 'min', 'max'])\n",
        "\n",
        "# --- Calculate \"Range\" (Spread) ---\n",
        "# Range isn't a built-in pandas string function, so we calculate it manually\n",
        "# Range = Max - Min\n",
        "overall_stats.loc['range'] = overall_stats.loc['max'] - overall_stats.loc['min']\n",
        "\n",
        "# --- Cleaning Up the Table ---\n",
        "# Rename the Index to match your \"Academic\" labels\n",
        "row_labels = {\n",
        "    'mean': 'Average (Mean)',\n",
        "    'median': 'Middle Value (Median)',\n",
        "    'min': 'Lowest Score',\n",
        "    'max': 'Highest Score',\n",
        "    'range': 'Spread (Range)'\n",
        "}\n",
        "overall_stats = overall_stats.rename(index=row_labels)\n",
        "\n",
        "# ---. Formatting ---\n",
        "# Round Performance to 2 decimals and Aptitude to 2 decimals\n",
        "# (You can adjust this if you want Aptitude to be integers)\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "\n",
        "# --- Display ---\n",
        "display(overall_stats)"
      ],
      "metadata": {
        "id": "VBoXfjsbS_J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calculate Basic Statistics ---\n",
        "# Group by 'course_level' and calculate count, mean, min, max, and std dev\n",
        "stats = df.groupby('course_level')['performance_score'].agg(['count', 'mean', 'min', 'max', 'std'])\n",
        "\n",
        "# --- Calculate \"Typical Range\" (Mean +/- SD) ---\n",
        "# We calculate the lower and upper bounds\n",
        "stats['lower'] = stats['mean'] - stats['std']\n",
        "stats['upper'] = stats['mean'] + stats['std']\n",
        "\n",
        "# Combine them into a single string column \"\n",
        "stats['Typical Range'] = (\n",
        "    stats['lower'].map('{:.2f}'.format) + ' - ' +\n",
        "    stats['upper'].map('{:.2f}'.format)\n",
        ")\n",
        "\n",
        "# ---  Formatting & Cleaning ---\n",
        "# Rename columns to match your Table 2 headers\n",
        "stats = stats.rename(columns={\n",
        "    'count': 'Students',\n",
        "    'mean': 'Average',\n",
        "    'min': 'Lowest',\n",
        "    'max': 'Highest'\n",
        "})\n",
        "\n",
        "# Select only the columns we want to display\n",
        "final_table = stats[['Students', 'Average', 'Lowest', 'Highest', 'Typical Range']]\n",
        "\n",
        "# Reorder the rows to match your image (Advanced -> Intermediate -> Foundation)\n",
        "final_table = final_table.reindex(['Advanced', 'Intermediate', 'Foundation'])\n",
        "\n",
        "# Apply formatting to the numeric columns (2 decimal places)\n",
        "# Note: 'Students' is an integer, so we don't apply float format to it.\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "# ---  Display ---\n",
        "print(\"Performance Scores Across Course Levels\")\n",
        "display(final_table)"
      ],
      "metadata": {
        "id": "sh8wgIJfWtj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  Calculate Basic Statistics ---\n",
        "# Group by 'course_level' and calculate stats for 'aptitude_score'\n",
        "stats = df.groupby('course_level')['aptitude_score'].agg(['count', 'mean', 'min', 'max', 'std'])\n",
        "\n",
        "# --- 3. Calculate \"Typical Range\" (Mean +/- Standard Deviation) ---\n",
        "# The image shows the range values as Integers (e.g., \"48 - 86\"), so we round them.\n",
        "stats['lower'] = (stats['mean'] - stats['std']).round(0).astype(int)\n",
        "stats['upper'] = (stats['mean'] + stats['std']).round(0).astype(int)\n",
        "\n",
        "# Create the \"Int - Int\" string format\n",
        "stats['Typical Range'] = (\n",
        "    stats['lower'].astype(str) + ' - ' +\n",
        "    stats['upper'].astype(str)\n",
        ")\n",
        "\n",
        "# --- 4. Formatting & Cleaning ---\n",
        "# Rename columns to match Table 3\n",
        "stats = stats.rename(columns={\n",
        "    'count': 'Students',\n",
        "    'mean': 'Average',\n",
        "    'min': 'Lowest',\n",
        "    'max': 'Highest'\n",
        "})\n",
        "\n",
        "# Reorder rows (Advanced -> Intermediate -> Foundation)\n",
        "stats = stats.reindex(['Advanced', 'Intermediate', 'Foundation'])\n",
        "\n",
        "# Select only the specific columns shown in the image\n",
        "final_table = stats[['Students', 'Average', 'Lowest', 'Highest', 'Typical Range']]\n",
        "\n",
        "# --- 5. Final Display Settings ---\n",
        "# Ensure 'Average' displays with 2 decimal places\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "print(\"Aptitude Scores Across Course Levels\")\n",
        "display(final_table)"
      ],
      "metadata": {
        "id": "BDW2Zp6oY_5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4: Statistical Assumption Testing"
      ],
      "metadata": {
        "id": "eV8OAGT7ZTiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Normality Test (Shapiro-Wilk) ---\n",
        "# We check normality for each group separately because ANOVA assumes\n",
        "# the residuals are normal (or groups are normal).\n",
        "normality_results = []\n",
        "\n",
        "for level in ['Advanced', 'Intermediate', 'Foundation']:\n",
        "    # Get Performance Scores for this level\n",
        "    subset = df[df['course_level'] == level]['performance_score']\n",
        "\n",
        "    # Run Shapiro-Wilk Test\n",
        "    stat, p_val = stats.shapiro(subset)\n",
        "\n",
        "    # Intepretation: If p > 0.05, it looks Normal. If p < 0.05, it is NOT Normal.\n",
        "    result = \"Normal\" if p_val > 0.05 else \"Not Normal\"\n",
        "\n",
        "    normality_results.append({\n",
        "        'Test': f\"Shapiro-Wilk ({level})\",\n",
        "        'Statistic': f\"{stat:.3f}\",\n",
        "        'p-value': f\"{p_val:.3f}\",\n",
        "        'Conclusion': result\n",
        "    })\n",
        "\n",
        "# --- Homogeneity of Variance (Levene's Test) ---\n",
        "# This checks if the \"spread\" is consistent across all three groups\n",
        "group1 = df[df['course_level'] == 'Advanced']['performance_score']\n",
        "group2 = df[df['course_level'] == 'Intermediate']['performance_score']\n",
        "group3 = df[df['course_level'] == 'Foundation']['performance_score']\n",
        "\n",
        "stat, p_val = stats.levene(group1, group2, group3)\n",
        "result = \"Variances are Equal\" if p_val > 0.05 else \"Variances are Different\"\n",
        "\n",
        "# Add Levene's result to the list\n",
        "normality_results.append({\n",
        "    'Test': \"Levene's Test (Homogeneity)\",\n",
        "    'Statistic': f\"{stat:.3f}\",\n",
        "    'p-value': f\"{p_val:.3f}\",\n",
        "    'Conclusion': result\n",
        "})\n",
        "\n",
        "# --- Create and Display Table ---\n",
        "results_df = pd.DataFrame(normality_results)\n",
        "\n",
        "# Display Options\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(\"Statistical Assumption Testing\")\n",
        "print(\"-\" * 60)\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "kXwtDKfHPC_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5: One-Way ANOVA Analysis"
      ],
      "metadata": {
        "id": "sEu1gqWoZXXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Prepare Data for ANOVA ---\n",
        "# We separate the performance scores into 3 arrays based on the group\n",
        "group_advanced = df[df['course_level'] == 'Advanced']['performance_score']\n",
        "group_inter = df[df['course_level'] == 'Intermediate']['performance_score']\n",
        "group_found = df[df['course_level'] == 'Foundation']['performance_score']\n",
        "\n",
        "# --- 3. Run the One-Way ANOVA ---\n",
        "f_stat, p_val = stats.f_oneway(group_advanced, group_inter, group_found)\n",
        "\n",
        "# --- 4. Calculate Effect Size (Eta Squared) manually ---\n",
        "# Scipy doesn't calculate this automatically, so we do the math:\n",
        "# Eta^2 = Sum of Squares Between / Sum of Squares Total\n",
        "\n",
        "# Grand Mean (Mean of ALL students)\n",
        "grand_mean = df['performance_score'].mean()\n",
        "\n",
        "# Sum of Squares Total (SST)\n",
        "ss_total = ((df['performance_score'] - grand_mean) ** 2).sum()\n",
        "\n",
        "# Sum of Squares Between (SSB)\n",
        "ss_between = 0\n",
        "for group in [group_advanced, group_inter, group_found]:\n",
        "    n = len(group)\n",
        "    group_mean = group.mean()\n",
        "    ss_between += n * (group_mean - grand_mean)**2\n",
        "\n",
        "eta_squared = ss_between / ss_total\n",
        "\n",
        "# --- 5. Display Results ---\n",
        "print(\"One-Way ANOVA Analysis Results (Performance)\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Variable Tested: Performance Score\")\n",
        "print(f\"F-Statistic:     {f_stat:.2f}\")\n",
        "\n",
        "# Format P-value to be readable\n",
        "if p_val < 0.001:\n",
        "    print(f\"P-Value:         < 0.001 (Highly Significant)\")\n",
        "else:\n",
        "    print(f\"P-Value:         {p_val:.4f}\")\n",
        "\n",
        "print(f\"Effect Size (η²): {eta_squared:.3f}\")\n",
        "\n",
        "# Interpretation\n",
        "print(\"-\" * 50)\n",
        "print(\"Conclusion:\")\n",
        "if p_val < 0.05:\n",
        "    print(\"There is a statistically significant difference between the groups.\")\n",
        "    print(f\"The Course Level explains {eta_squared*100:.1f}% of the variance in scores.\")\n",
        "else:\n",
        "    print(\"No significant difference found between the groups.\")"
      ],
      "metadata": {
        "id": "DD1LdGfLPyQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Prepare Data for ANOVA (Aptitude) ---\n",
        "# Separate aptitude scores into 3 groups\n",
        "apt_advanced = df[df['course_level'] == 'Advanced']['aptitude_score']\n",
        "apt_inter = df[df['course_level'] == 'Intermediate']['aptitude_score']\n",
        "apt_found = df[df['course_level'] == 'Foundation']['aptitude_score']\n",
        "\n",
        "# --- 3. Run One-Way ANOVA ---\n",
        "f_stat, p_val = stats.f_oneway(apt_advanced, apt_inter, apt_found)\n",
        "\n",
        "# --- 4. Calculate Effect Size (Eta Squared) ---\n",
        "# Formula: SS_Between / SS_Total\n",
        "\n",
        "# Grand Mean (Average of ALL aptitude scores)\n",
        "grand_mean = df['aptitude_score'].mean()\n",
        "\n",
        "# Sum of Squares Total (SST)\n",
        "ss_total = ((df['aptitude_score'] - grand_mean) ** 2).sum()\n",
        "\n",
        "# Sum of Squares Between (SSB)\n",
        "ss_between = 0\n",
        "for group in [apt_advanced, apt_inter, apt_found]:\n",
        "    n = len(group)\n",
        "    group_mean = group.mean()\n",
        "    ss_between += n * (group_mean - grand_mean)**2\n",
        "\n",
        "eta_squared = ss_between / ss_total\n",
        "\n",
        "# --- 5. Display Results ---\n",
        "print(\"One-Way ANOVA Analysis Results (Aptitude)\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Variable Tested: Aptitude Score\")\n",
        "print(f\"F-Statistic:     {f_stat:.2f}\")\n",
        "\n",
        "# Format P-value\n",
        "if p_val < 0.001:\n",
        "    print(f\"P-Value:         < 0.001 (Highly Significant)\")\n",
        "else:\n",
        "    print(f\"P-Value:         {p_val:.4f}\")\n",
        "\n",
        "print(f\"Effect Size (η²): {eta_squared:.3f}\")\n",
        "\n",
        "# Interpretation\n",
        "print(\"-\" * 50)\n",
        "print(\"Conclusion:\")\n",
        "if p_val < 0.05:\n",
        "    print(\"There is a statistically significant difference in Aptitude between the levels.\")\n",
        "    print(f\"The Course Level explains {eta_squared*100:.1f}% of the variance in aptitude scores.\")\n",
        "else:\n",
        "    print(\"No significant difference found between the groups.\")"
      ],
      "metadata": {
        "id": "lMxDxCM_Qb_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 6: Post-Hoc Tests (Tukey HSD)"
      ],
      "metadata": {
        "id": "42OKU2lrZZ-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART A: Tukey HSD for Performance Scores\n",
        "# ==========================================\n",
        "print(\"6.1 Tukey HSD Results: Performance Scores\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Run the test\n",
        "# endog = data (scores), groups = group labels (levels)\n",
        "tukey_perf = pairwise_tukeyhsd(endog=df['performance_score'],\n",
        "                               groups=df['course_level'],\n",
        "                               alpha=0.05)\n",
        "\n",
        "# Display the results table\n",
        "print(tukey_perf)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# PART B: Tukey HSD for Aptitude Scores\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "print(\"6.2 Tukey HSD Results: Aptitude Scores\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Run the test\n",
        "tukey_apt = pairwise_tukeyhsd(endog=df['aptitude_score'],\n",
        "                              groups=df['course_level'],\n",
        "                              alpha=0.05)\n",
        "\n",
        "# Display the results table\n",
        "print(tukey_apt)\n",
        "\n",
        "# --- Optional: Convert to Pandas DataFrame for cleaner view ---\n",
        "# If you want to use the data later or display it prettier:\n",
        "# perf_df = pd.DataFrame(data=tukey_perf._results_table.data[1:],\n",
        "#                        columns=tukey_perf._results_table.data[0])\n",
        "# print(\"\\n(Pandas DataFrame Version):\")\n",
        "# print(perf_df)"
      ],
      "metadata": {
        "id": "W7GguJdrTRuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Define Helper Function for Cohen's d ---\n",
        "# Cohen's d measures the \"standardized mean difference\"\n",
        "def calculate_cohens_d(group1, group2):\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    # Calculate sample variances (ddof=1)\n",
        "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
        "\n",
        "    # Calculate Pooled Standard Deviation\n",
        "    numerator = ((n1 - 1) * var1) + ((n2 - 1) * var2)\n",
        "    denominator = n1 + n2 - 2\n",
        "    pooled_sd = np.sqrt(numerator / denominator)\n",
        "\n",
        "    # Calculate Cohen's d\n",
        "    d = (np.mean(group1) - np.mean(group2)) / pooled_sd\n",
        "    return d\n",
        "\n",
        "# --- 3. Define Interpretation Logic ---\n",
        "def get_interpretation(d_value):\n",
        "    abs_d = abs(d_value)\n",
        "    if abs_d >= 1.2:\n",
        "        return \"Very Large\"\n",
        "    elif abs_d >= 0.8:\n",
        "        return \"Large\"\n",
        "    elif abs_d >= 0.5:\n",
        "        return \"Medium\"\n",
        "    elif abs_d >= 0.2:\n",
        "        return \"Small\"\n",
        "    else:\n",
        "        return \"Negligible\"\n",
        "\n",
        "# --- 4. Perform Comparisons and Build Table Data ---\n",
        "# Define the specific pairs to compare\n",
        "comparisons = [\n",
        "    ('Advanced', 'Intermediate'),\n",
        "    ('Intermediate', 'Foundation'),\n",
        "    ('Advanced', 'Foundation')\n",
        "]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for label1, label2 in comparisons:\n",
        "    # Isolate the data for the two groups being compared\n",
        "    g1 = df[df['course_level'] == label1]['performance_score']\n",
        "    g2 = df[df['course_level'] == label2]['performance_score']\n",
        "\n",
        "    # A. Calculate raw difference\n",
        "    diff = g1.mean() - g2.mean()\n",
        "\n",
        "    # B. Calculate p-value (Independent t-test)\n",
        "    t_stat, p_val = stats.ttest_ind(g1, g2)\n",
        "\n",
        "    # C. Calculate Effect Size (Cohen's d)\n",
        "    d_val = calculate_cohens_d(g1, g2)\n",
        "\n",
        "    # D. Determine Interpretation string\n",
        "    interpret_str = get_interpretation(d_val)\n",
        "\n",
        "    # --- Formatting rows to match image ---\n",
        "    formatted_row = {\n",
        "        'Comparison': f\"{label1} vs {label2}\",\n",
        "        'Difference': f\"{diff:.2f} points\",\n",
        "        # Format p-value to \"<0.001\" if extremely small\n",
        "        'p-value': \"<0.001\" if p_val < 0.001 else f\"{p_val:.3f}\",\n",
        "        'Effect Size': f\"{d_val:.2f}\",\n",
        "        'Interpretation': interpret_str\n",
        "    }\n",
        "    rows.append(formatted_row)\n",
        "\n",
        "# --- 5. Create and Display Pandas DataFrame ---\n",
        "results_df = pd.DataFrame(rows)\n",
        "\n",
        "# Set display options to make sure columns don't get cut off\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# Print Titles\n",
        "print(\"6.2.2  Comparing Specific Pairs of Levels\\n\")\n",
        "print(\"Table 4: Pairwise Performance Comparisons\")\n",
        "# Print the Table\n",
        "print(results_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "8JK2QeKzW61H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7: Correlation Analysis"
      ],
      "metadata": {
        "id": "o5VNzQa0ZdYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calculate Correlation Statistics ---\n",
        "# Pearson correlation returns the coefficient (r) and the p-value\n",
        "r, p_value = stats.pearsonr(df['aptitude_score'], df['performance_score'])\n",
        "\n",
        "# Calculate Shared Variance (Coefficient of Determination, r-squared)\n",
        "# This represents the percentage of variation in one variable explained by the other\n",
        "shared_variance = r ** 2\n",
        "\n",
        "# --- 3. Build the Table Data ---\n",
        "# We manually construct the rows to match the specific format of your image\n",
        "data = [\n",
        "    {\n",
        "        'Relationship': 'Aptitude <-> Performance',\n",
        "        'Correlation (r)': f\"{r:.3f}\",\n",
        "        'Interpretation': 'Very Strong Positive' # Interpretation based on r > 0.8\n",
        "    },\n",
        "    {\n",
        "        'Relationship': 'Statistical Significance',\n",
        "        'Correlation (r)': 'p < 0.001' if p_value < 0.001 else f\"{p_value:.4f}\",\n",
        "        'Interpretation': 'Extremely Confident' # Interpretation based on p < 0.001\n",
        "    },\n",
        "    {\n",
        "        'Relationship': 'Shared Variance',\n",
        "        'Correlation (r)': f\"{shared_variance*100:.1f}%\",\n",
        "        'Interpretation': 'High Predictability' # Interpretation based on high r-squared\n",
        "    }\n",
        "]\n",
        "\n",
        "# ---  Create and Display Table ---\n",
        "results_df = pd.DataFrame(data)\n",
        "\n",
        "# Adjust pandas settings to ensure the long text sentences don't get cut off\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "print(\"Correlation Between Aptitude and Performance\")\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "EluevrSpcbpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptions = {\n",
        "    'Advanced': 'Even among advanced students, aptitude predicts performance',\n",
        "    'Intermediate': 'Clear aptitude-performance link in the middle range',\n",
        "    'Foundation': 'Weaker but still meaningful relationship'\n",
        "}\n",
        "\n",
        "# ---  Calculate Correlations by Group ---\n",
        "rows = []\n",
        "# Order: Advanced -> Intermediate -> Foundation\n",
        "order = ['Advanced', 'Intermediate', 'Foundation']\n",
        "\n",
        "for level in order:\n",
        "    # Get data for this specific level\n",
        "    subset = df[df['course_level'] == level]\n",
        "\n",
        "    # Calculate Pearson Correlation\n",
        "    r, _ = stats.pearsonr(subset['aptitude_score'], subset['performance_score'])\n",
        "\n",
        "    # Determine Strength Label dynamically based on r value\n",
        "    if r > 0.7:\n",
        "        strength = \"Strong\"\n",
        "    elif r > 0.4:\n",
        "        strength = \"Moderate\"\n",
        "    else:\n",
        "        strength = \"Weak-Moderate\"\n",
        "\n",
        "    # Append to list\n",
        "    rows.append({\n",
        "        'Level': level,\n",
        "        'Correlation': f\"{r:.3f}\",\n",
        "        'Strength': strength,\n",
        "        'What This Means': descriptions[level]\n",
        "    })\n",
        "\n",
        "# ---  Create and Format Table ---\n",
        "results_df = pd.DataFrame(rows)\n",
        "\n",
        "# Adjust pandas settings to ensure the long text sentences don't get cut off\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "print(\"Correlations Within Each Course Level\")\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "GC96JOhIdeOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calculate Correlation Matrix ---\n",
        "# Select only the two columns we want to compare\n",
        "corr_matrix = df[['performance_score', 'aptitude_score']].corr()\n",
        "\n",
        "# ---  Setup Styling ---\n",
        "# Use white background so the white lines between heatmap squares are visible\n",
        "sns.set_style(\"white\")\n",
        "plt.figure(figsize=(7, 6))\n",
        "\n",
        "# --- Draw the Heatmap ---\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,          # Show the numbers (0.89, 1) in the squares\n",
        "    cmap='RdYlGn',       # Red-Yellow-Green colormap (matches the red in your image)\n",
        "    center=0,            # centers the colormap\n",
        "    vmin=0.88, vmax=1,   # Limits the color range to make the red intense (since correlation is high)\n",
        "    linewidths=2,        # Width of the white lines between squares\n",
        "    linecolor='white',   # Color of the lines\n",
        "    square=True,         # Forces squares to be perfect squares\n",
        "    cbar_kws={\"shrink\": 0.8} # Slightly shrinks the color bar on the right\n",
        ")\n",
        "\n",
        "# --- Customization ---\n",
        "plt.title('Correlation Heatmap: Performance vs Aptitude Score', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5jOKk-QWeNKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 8: Effect Sizes (Cohen's d)"
      ],
      "metadata": {
        "id": "qY5rJ9oGZgJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions ---\n",
        "\n",
        "# Function to calculate Cohen's d (Effect Size)\n",
        "def calculate_cohens_d(group1, group2):\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
        "\n",
        "    # Pooled Standard Deviation\n",
        "    numerator = ((n1 - 1) * var1) + ((n2 - 1) * var2)\n",
        "    denominator = n1 + n2 - 2\n",
        "    pooled_sd = np.sqrt(numerator / denominator)\n",
        "\n",
        "    # Cohen's d\n",
        "    return (np.mean(group1) - np.mean(group2)) / pooled_sd\n",
        "\n",
        "# Function to interpret Effect Size\n",
        "def interpret_effect(d):\n",
        "    d = abs(d)\n",
        "    if d >= 1.2: return \"Very Large\"\n",
        "    if d >= 0.8: return \"Large\"\n",
        "    if d >= 0.5: return \"Medium\"\n",
        "    return \"Small\"\n",
        "\n",
        "# --- 3. Perform Pairwise Comparisons ---\n",
        "comparisons = [\n",
        "    ('Advanced', 'Intermediate'),\n",
        "    ('Intermediate', 'Foundation'),\n",
        "    ('Advanced', 'Foundation')\n",
        "]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for label1, label2 in comparisons:\n",
        "    # Get the Aptitude Scores for the two groups\n",
        "    g1 = df[df['course_level'] == label1]['aptitude_score']\n",
        "    g2 = df[df['course_level'] == label2]['aptitude_score']\n",
        "\n",
        "    # Calculate Stats\n",
        "    diff = g1.mean() - g2.mean()\n",
        "    t_stat, p_val = stats.ttest_ind(g1, g2)\n",
        "    d_val = calculate_cohens_d(g1, g2)\n",
        "\n",
        "    # Format Row\n",
        "    rows.append({\n",
        "        'Comparison': f\"{label1} vs {label2}\",\n",
        "        'Difference': f\"{diff:.1f} points\",\n",
        "        'p-value': \"<0.001\" if p_val < 0.001 else f\"{p_val:.3f}\",\n",
        "        'Effect Size': f\"{d_val:.2f}\",\n",
        "        'Interpretation': interpret_effect(d_val)\n",
        "    })\n",
        "\n",
        "# --- 4. Display Table ---\n",
        "results = pd.DataFrame(rows)\n",
        "\n",
        "# Adjust display settings to ensure full table visibility\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "print(\"Comparing Specific Pairs of Levels\\n\")\n",
        "print(\"Pairwise Aptitude Comparisons\")\n",
        "display(results)"
      ],
      "metadata": {
        "id": "TOxKtjYsaMVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 9: Comprehensive Visualizations"
      ],
      "metadata": {
        "id": "6QqmH4_NZkh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup Figure ---\n",
        "sns.set_style(\"darkgrid\")\n",
        "# Create a 3x3 Grid (3 Rows, 3 Columns)\n",
        "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
        "\n",
        "# Increase vertical spacing so titles don't overlap\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "# ==========================================\n",
        "# ROW 1: Boxplots & Performance Violin\n",
        "# ==========================================\n",
        "\n",
        "# 1.1 Performance Boxplot (Left)\n",
        "sns.boxplot(\n",
        "    data=df, x='course_level', y='performance_score',\n",
        "    order=['Advanced', 'Foundation', 'Intermediate'],\n",
        "    boxprops=dict(facecolor=(0,0,0,0)), # Transparent\n",
        "    width=0.5, linewidth=1.2, fliersize=6,\n",
        "    ax=axes[0, 0]\n",
        ")\n",
        "axes[0, 0].set_title('Performance Score Distribution by Course Level', fontsize=14)\n",
        "axes[0, 0].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "# 1.2 Aptitude Boxplot (Middle)\n",
        "sns.boxplot(\n",
        "    data=df, x='course_level', y='aptitude_score',\n",
        "    order=['Advanced', 'Foundation', 'Intermediate'],\n",
        "    boxprops=dict(facecolor=(0,0,0,0)), # Transparent\n",
        "    width=0.5, linewidth=1.2, fliersize=6,\n",
        "    ax=axes[0, 1]\n",
        ")\n",
        "axes[0, 1].set_title('Aptitude Score Distribution by Course Level', fontsize=14)\n",
        "axes[0, 1].tick_params(axis='both', which='major', labelsize=11)\n",
        "axes[0, 1].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "# 1.3 Performance Violin Plot (Right)\n",
        "sns.violinplot(\n",
        "    data=df, x='course_level', y='performance_score',\n",
        "    order=['Advanced', 'Intermediate', 'Foundation'],\n",
        "    color='#F6848F', inner='box', linewidth=1.2,\n",
        "    ax=axes[0, 2]\n",
        ")\n",
        "axes[0, 2].set_title('Performance Score Distribution (Violin Plot)', fontsize=14)\n",
        "axes[0, 2].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# ROW 2: Aptitude Violin & Bar Charts\n",
        "# ==========================================\n",
        "\n",
        "# 2.1 Aptitude Violin Plot (Left)\n",
        "sns.violinplot(\n",
        "    data=df, x='course_level', y='aptitude_score',\n",
        "    order=['Advanced', 'Intermediate', 'Foundation'],\n",
        "    color='#F6848F', inner='box', linewidth=1.2,\n",
        "    ax=axes[1, 0]\n",
        ")\n",
        "axes[1, 0].set_title('Aptitude Distribution (Violin Plot)', fontsize=14)\n",
        "axes[1, 0].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "# 2.2 Mean Performance Bar Plot (Middle)\n",
        "sns.barplot(\n",
        "    data=df, x='course_level', y='performance_score',\n",
        "    order=['Advanced', 'Foundation', 'Intermediate'],\n",
        "    errorbar='sd', capsize=0.1, width=0.5,\n",
        "    hue='course_level', legend=False,\n",
        "    err_kws={'color': 'black', 'linewidth': 1.5},\n",
        "    ax=axes[1, 1]\n",
        ")\n",
        "axes[1, 1].set_title('Mean Performance Score by Level (with SD)', fontsize=14)\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "axes[1, 1].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "# 2.3 Mean Aptitude Bar Plot (Right)\n",
        "sns.barplot(\n",
        "    data=df, x='course_level', y='aptitude_score',\n",
        "    order=['Advanced', 'Foundation', 'Intermediate'],\n",
        "    errorbar='sd', capsize=0.1, width=0.5,\n",
        "    hue='course_level', legend=False,\n",
        "    err_kws={'color': 'black', 'linewidth': 1.5},\n",
        "    ax=axes[1, 2]\n",
        ")\n",
        "axes[1, 2].set_title('Mean Aptitude Score by Level (with SD)', fontsize=14)\n",
        "axes[1, 2].tick_params(axis='x', rotation=45)\n",
        "axes[1, 2].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# ROW 3: Correlation & Histograms\n",
        "# ==========================================\n",
        "\n",
        "# 3.1 Scatter Plot with Regression (Left)\n",
        "# Calculate Correlation\n",
        "import scipy.stats as sps # Local import and alias to avoid name collision with 'stats' DataFrame variable\n",
        "r, p = sps.pearsonr(df['performance_score'], df['aptitude_score'])\n",
        "\n",
        "sns.scatterplot(\n",
        "    data=df, x='performance_score', y='aptitude_score',\n",
        "    hue='course_level', s=80, alpha=0.7, palette='tab10',\n",
        "    ax=axes[2, 0]\n",
        ")\n",
        "sns.regplot(\n",
        "    data=df, x='performance_score', y='aptitude_score',\n",
        "    scatter=False, ci=None, line_kws={\"color\": \"red\", \"ls\": \"--\", \"linewidth\": 2.5},\n",
        "    ax=axes[2, 0]\n",
        ")\n",
        "axes[2, 0].set_title(f'Performance vs Aptitude Score (r = {r:.3f})', fontsize=14)\n",
        "axes[2, 0].legend(loc='upper left', frameon=False)\n",
        "\n",
        "# Custom Colors for Histograms\n",
        "colors = {'Advanced': '#F49AC2', 'Intermediate': '#C4B083', 'Foundation': '#93C47D'}\n",
        "\n",
        "# 3.2 Performance Histogram (Middle)\n",
        "for level, color in colors.items():\n",
        "    sns.histplot(\n",
        "        data=df[df['course_level'] == level], x='performance_score',\n",
        "        bins=15, alpha=0.6, color=color, label=level, edgecolor=None, linewidth=0,\n",
        "        ax=axes[2, 1]\n",
        "    )\n",
        "axes[2, 1].set_title('Performance Score Histogram by Level', fontsize=14)\n",
        "axes[2, 1].legend(labels=['Advanced', 'Intermediate', 'Foundation'])\n",
        "\n",
        "# 3.3 Aptitude Histogram (Right)\n",
        "for level, color in colors.items():\n",
        "    sns.histplot(\n",
        "        data=df[df['course_level'] == level], x='aptitude_score',\n",
        "        bins=15, alpha=0.6, color=color, label=level, edgecolor=None, linewidth=0,\n",
        "        ax=axes[2, 2]\n",
        "    )\n",
        "axes[2, 2].set_title('Aptitude Score Histogram by Level', fontsize=14)\n",
        "axes[2, 2].legend(labels=['Advanced', 'Intermediate', 'Foundation'])\n",
        "\n",
        "# --- Final Layout ---\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0eKszIUbOE_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 10: Summary and Conclusions"
      ],
      "metadata": {
        "id": "j1J3o-pOZo5w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dlU_YhIcefdr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}