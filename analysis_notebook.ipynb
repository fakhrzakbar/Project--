{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYrTNsacnNaDkjqH/HTZx9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fakhrzakbar/Project--/blob/main/analysis_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Performance and Aptitude Analysis\n",
        "# The Key English Course Company - Indonesia\n",
        "\n",
        "### A Comprehensive Data-Driven Study\n",
        "\n",
        "**Analysis Date:** January 13, 2026\n",
        "**Total Students:** 150 (50 per course level)\n",
        "**Variables Analyzed:** Performance Scores, Aptitude Scores\n",
        "**Statistical Methods:** ANOVA, Correlation, Effect Sizes, Post-Hoc Tests#\n"
      ],
      "metadata": {
        "id": "VllDSTbAWoub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1: Environment Setup"
      ],
      "metadata": {
        "id": "sYdnrDxqXpTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "VuHqBUX5IMq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2: Data Loading and Overview"
      ],
      "metadata": {
        "id": "hXiPFlxyZG4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load your data\n",
        "# Ensure your file is named 'data.csv' and is in the same folder as this script\n",
        "df = pd.read_csv('student_combined_data.csv')"
      ],
      "metadata": {
        "id": "fS0xGCpzXwPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Descriptive Statistics by Course Level"
      ],
      "metadata": {
        "id": "lN5whn4aZOS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4: Statistical Assumption Testing"
      ],
      "metadata": {
        "id": "eV8OAGT7ZTiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5: One-Way ANOVA Analysis"
      ],
      "metadata": {
        "id": "sEu1gqWoZXXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Calculate Basic Statistics ---\n",
        "# We select the two relevant columns and use .agg to get most stats at once\n",
        "overall_stats = df[['performance_score', 'aptitude_score']].agg(['mean', 'median', 'min', 'max'])\n",
        "\n",
        "# --- 3. Calculate \"Range\" (Spread) ---\n",
        "# Range isn't a built-in pandas string function, so we calculate it manually\n",
        "# Range = Max - Min\n",
        "overall_stats.loc['range'] = overall_stats.loc['max'] - overall_stats.loc['min']\n",
        "\n",
        "# --- 4. Cleaning Up the Table ---\n",
        "# Rename the Index to match your \"Academic\" labels\n",
        "row_labels = {\n",
        "    'mean': 'Average (Mean)',\n",
        "    'median': 'Middle Value (Median)',\n",
        "    'min': 'Lowest Score',\n",
        "    'max': 'Highest Score',\n",
        "    'range': 'Spread (Range)'\n",
        "}\n",
        "overall_stats = overall_stats.rename(index=row_labels)\n",
        "\n",
        "# --- 5. Formatting ---\n",
        "# Round Performance to 2 decimals and Aptitude to 2 decimals\n",
        "# (You can adjust this if you want Aptitude to be integers)\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "\n",
        "# --- 6. Display ---\n",
        "print(overall_stats)"
      ],
      "metadata": {
        "id": "VBoXfjsbS_J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Prepare Data for ANOVA ---\n",
        "# Group the performance scores by course level\n",
        "groups = [group['performance_score'].values for name, group in df.groupby('course_level')]\n",
        "\n",
        "# --- 3. Run One-Way ANOVA ---\n",
        "f_stat, p_val = stats.f_oneway(*groups)\n",
        "\n",
        "# --- 4. Calculate Effect Size (Eta Squared) ---\n",
        "# Formula: Eta_Squared = Sum_Squares_Between / Sum_Squares_Total\n",
        "\n",
        "# Calculate Grand Mean (average of everyone)\n",
        "grand_mean = df['performance_score'].mean()\n",
        "\n",
        "# Calculate Sum of Squares Total (SST)\n",
        "ss_total = ((df['performance_score'] - grand_mean) ** 2).sum()\n",
        "\n",
        "# Calculate Sum of Squares Between (SSB)\n",
        "ss_between = 0\n",
        "for name, group in df.groupby('course_level'):\n",
        "    n = len(group) # Number of students in this level\n",
        "    group_mean = group['performance_score'].mean()\n",
        "    ss_between += n * (group_mean - grand_mean)**2\n",
        "\n",
        "eta_squared = ss_between / ss_total\n",
        "\n",
        "# --- 5. Print Results in the Format of the Image ---\n",
        "print(\"6.2  Testing for Performance Differences\")\n",
        "print(\"6.2.1  The Test: One-Way ANOVA\")\n",
        "print(\"-\" * 40)\n",
        "print(\"What we tested: Are the average performance scores different across the three course levels?\")\n",
        "print(\"\\nResults:\")\n",
        "\n",
        "# Print F-value (Matches 213.41)\n",
        "print(f\"* Test Statistic (F-value): {f_stat:.2f}\")\n",
        "\n",
        "# Print P-value logic (Matches \"Less than 0.001\")\n",
        "if p_val < 0.001:\n",
        "    print(\"* Probability (p-value): Less than 0.001 (less than 0.1%)\")\n",
        "else:\n",
        "    print(f\"* Probability (p-value): {p_val:.4f}\")\n",
        "\n",
        "# Print Effect Size (Matches 0.744)\n",
        "print(f\"* Effect Size: {eta_squared:.3f} (meaning {eta_squared*100:.1f}% of the difference is explained by course level)\")"
      ],
      "metadata": {
        "id": "cZFcvOniOwgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 6: Post-Hoc Tests (Tukey HSD)"
      ],
      "metadata": {
        "id": "42OKU2lrZZ-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Calculate Basic Statistics ---\n",
        "# Group by 'course_level' and calculate count, mean, min, max, and std dev\n",
        "stats = df.groupby('course_level')['performance_score'].agg(['count', 'mean', 'min', 'max', 'std'])\n",
        "\n",
        "# --- 3. Calculate \"Typical Range\" (Mean +/- SD) ---\n",
        "# We calculate the lower and upper bounds\n",
        "stats['lower'] = stats['mean'] - stats['std']\n",
        "stats['upper'] = stats['mean'] + stats['std']\n",
        "\n",
        "# Combine them into a single string column like \"2.85 - 3.62\"\n",
        "stats['Typical Range'] = (\n",
        "    stats['lower'].map('{:.2f}'.format) + ' - ' +\n",
        "    stats['upper'].map('{:.2f}'.format)\n",
        ")\n",
        "\n",
        "# --- 4. Formatting & Cleaning ---\n",
        "# Rename columns to match your Table 2 headers\n",
        "stats = stats.rename(columns={\n",
        "    'count': 'Students',\n",
        "    'mean': 'Average',\n",
        "    'min': 'Lowest',\n",
        "    'max': 'Highest'\n",
        "})\n",
        "\n",
        "# Select only the columns we want to display\n",
        "final_table = stats[['Students', 'Average', 'Lowest', 'Highest', 'Typical Range']]\n",
        "\n",
        "# Reorder the rows to match your image (Advanced -> Intermediate -> Foundation)\n",
        "final_table = final_table.reindex(['Advanced', 'Intermediate', 'Foundation'])\n",
        "\n",
        "# Apply formatting to the numeric columns (2 decimal places)\n",
        "# Note: 'Students' is an integer, so we don't apply float format to it.\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "# --- 5. Display ---\n",
        "print(\"Table 2: Performance Scores Across Course Levels\")\n",
        "print(final_table)"
      ],
      "metadata": {
        "id": "sh8wgIJfWtj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Calculate Basic Statistics ---\n",
        "# Group by 'course_level' and calculate stats for 'aptitude_score'\n",
        "stats = df.groupby('course_level')['aptitude_score'].agg(['count', 'mean', 'min', 'max', 'std'])\n",
        "\n",
        "# --- 3. Calculate \"Typical Range\" (Mean +/- Standard Deviation) ---\n",
        "# The image shows the range values as Integers (e.g., \"48 - 86\"), so we round them.\n",
        "stats['lower'] = (stats['mean'] - stats['std']).round(0).astype(int)\n",
        "stats['upper'] = (stats['mean'] + stats['std']).round(0).astype(int)\n",
        "\n",
        "# Create the \"Int - Int\" string format\n",
        "stats['Typical Range'] = (\n",
        "    stats['lower'].astype(str) + ' - ' +\n",
        "    stats['upper'].astype(str)\n",
        ")\n",
        "\n",
        "# --- 4. Formatting & Cleaning ---\n",
        "# Rename columns to match Table 3\n",
        "stats = stats.rename(columns={\n",
        "    'count': 'Students',\n",
        "    'mean': 'Average',\n",
        "    'min': 'Lowest',\n",
        "    'max': 'Highest'\n",
        "})\n",
        "\n",
        "# Reorder rows (Advanced -> Intermediate -> Foundation)\n",
        "stats = stats.reindex(['Advanced', 'Intermediate', 'Foundation'])\n",
        "\n",
        "# Select only the specific columns shown in the image\n",
        "final_table = stats[['Students', 'Average', 'Lowest', 'Highest', 'Typical Range']]\n",
        "\n",
        "# --- 5. Final Display Settings ---\n",
        "# Ensure 'Average' displays with 2 decimal places\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "print(\"Table 3: Aptitude Scores Across Course Levels\")\n",
        "print(final_table)"
      ],
      "metadata": {
        "id": "BDW2Zp6oY_5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Define Helper Function for Cohen's d ---\n",
        "# Cohen's d measures the \"standardized mean difference\"\n",
        "def calculate_cohens_d(group1, group2):\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    # Calculate sample variances (ddof=1)\n",
        "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
        "\n",
        "    # Calculate Pooled Standard Deviation\n",
        "    numerator = ((n1 - 1) * var1) + ((n2 - 1) * var2)\n",
        "    denominator = n1 + n2 - 2\n",
        "    pooled_sd = np.sqrt(numerator / denominator)\n",
        "\n",
        "    # Calculate Cohen's d\n",
        "    d = (np.mean(group1) - np.mean(group2)) / pooled_sd\n",
        "    return d\n",
        "\n",
        "# --- 3. Define Interpretation Logic ---\n",
        "def get_interpretation(d_value):\n",
        "    abs_d = abs(d_value)\n",
        "    if abs_d >= 1.2:\n",
        "        return \"Very Large\"\n",
        "    elif abs_d >= 0.8:\n",
        "        return \"Large\"\n",
        "    elif abs_d >= 0.5:\n",
        "        return \"Medium\"\n",
        "    elif abs_d >= 0.2:\n",
        "        return \"Small\"\n",
        "    else:\n",
        "        return \"Negligible\"\n",
        "\n",
        "# --- 4. Perform Comparisons and Build Table Data ---\n",
        "# Define the specific pairs to compare\n",
        "comparisons = [\n",
        "    ('Advanced', 'Intermediate'),\n",
        "    ('Intermediate', 'Foundation'),\n",
        "    ('Advanced', 'Foundation')\n",
        "]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for label1, label2 in comparisons:\n",
        "    # Isolate the data for the two groups being compared\n",
        "    g1 = df[df['course_level'] == label1]['performance_score']\n",
        "    g2 = df[df['course_level'] == label2]['performance_score']\n",
        "\n",
        "    # A. Calculate raw difference\n",
        "    diff = g1.mean() - g2.mean()\n",
        "\n",
        "    # B. Calculate p-value (Independent t-test)\n",
        "    t_stat, p_val = stats.ttest_ind(g1, g2)\n",
        "\n",
        "    # C. Calculate Effect Size (Cohen's d)\n",
        "    d_val = calculate_cohens_d(g1, g2)\n",
        "\n",
        "    # D. Determine Interpretation string\n",
        "    interpret_str = get_interpretation(d_val)\n",
        "\n",
        "    # --- Formatting rows to match image ---\n",
        "    formatted_row = {\n",
        "        'Comparison': f\"{label1} vs {label2}\",\n",
        "        'Difference': f\"{diff:.2f} points\",\n",
        "        # Format p-value to \"<0.001\" if extremely small\n",
        "        'p-value': \"<0.001\" if p_val < 0.001 else f\"{p_val:.3f}\",\n",
        "        'Effect Size': f\"{d_val:.2f}\",\n",
        "        'Interpretation': interpret_str\n",
        "    }\n",
        "    rows.append(formatted_row)\n",
        "\n",
        "# --- 5. Create and Display Pandas DataFrame ---\n",
        "results_df = pd.DataFrame(rows)\n",
        "\n",
        "# Set display options to make sure columns don't get cut off\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# Print Titles\n",
        "print(\"6.2.2  Comparing Specific Pairs of Levels\\n\")\n",
        "print(\"Table 4: Pairwise Performance Comparisons\")\n",
        "# Print the Table\n",
        "print(results_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "8JK2QeKzW61H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Prepare Data for ANOVA ---\n",
        "# Group the Aptitude scores by course level\n",
        "groups = [group['aptitude_score'].values for name, group in df.groupby('course_level')]\n",
        "\n",
        "# --- 3. Run One-Way ANOVA ---\n",
        "f_stat, p_val = stats.f_oneway(*groups)\n",
        "\n",
        "# --- 4. Calculate Effect Size (Eta Squared) ---\n",
        "# Formula: Eta_Squared = SS_Between / SS_Total\n",
        "\n",
        "# Grand Mean (average of all students)\n",
        "grand_mean = df['aptitude_score'].mean()\n",
        "\n",
        "# Sum of Squares Total (SST)\n",
        "ss_total = ((df['aptitude_score'] - grand_mean) ** 2).sum()\n",
        "\n",
        "# Sum of Squares Between (SSB)\n",
        "ss_between = 0\n",
        "for name, group in df.groupby('course_level'):\n",
        "    n = len(group)\n",
        "    group_mean = group['aptitude_score'].mean()\n",
        "    ss_between += n * (group_mean - grand_mean)**2\n",
        "\n",
        "eta_squared = ss_between / ss_total\n",
        "\n",
        "# --- 5. Create Summary Table ---\n",
        "# We structure the results as a DataFrame for a clean table output\n",
        "anova_results = pd.DataFrame({\n",
        "    'Metric': [\n",
        "        'Test Statistic (F-value)',\n",
        "        'Probability (p-value)',\n",
        "        'Effect Size (Eta Squared)'\n",
        "    ],\n",
        "    'Value': [\n",
        "        f\"{f_stat:.2f}\",\n",
        "        \"< 0.001\" if p_val < 0.001 else f\"{p_val:.4f}\",\n",
        "        f\"{eta_squared:.3f}\"\n",
        "    ],\n",
        "    'Interpretation': [\n",
        "        '', # No interpretation needed for F-value itself in this format\n",
        "        'Significant difference exists' if p_val < 0.05 else 'No significant difference',\n",
        "        f\"{eta_squared*100:.1f}% of difference explained by course level\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# --- 6. Display ---\n",
        "print(\"6.3.1  The Test: One-Way ANOVA (Aptitude Scores)\\n\")\n",
        "# Left align the text for better readability\n",
        "print(anova_results.to_string(index=False))"
      ],
      "metadata": {
        "id": "Db0cBFeVYdhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Helper Functions ---\n",
        "\n",
        "# Function to calculate Cohen's d (Effect Size)\n",
        "def calculate_cohens_d(group1, group2):\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
        "\n",
        "    # Pooled Standard Deviation\n",
        "    numerator = ((n1 - 1) * var1) + ((n2 - 1) * var2)\n",
        "    denominator = n1 + n2 - 2\n",
        "    pooled_sd = np.sqrt(numerator / denominator)\n",
        "\n",
        "    # Cohen's d\n",
        "    return (np.mean(group1) - np.mean(group2)) / pooled_sd\n",
        "\n",
        "# Function to interpret Effect Size\n",
        "def interpret_effect(d):\n",
        "    d = abs(d)\n",
        "    if d >= 1.2: return \"Very Large\"\n",
        "    if d >= 0.8: return \"Large\"\n",
        "    if d >= 0.5: return \"Medium\"\n",
        "    return \"Small\"\n",
        "\n",
        "# --- 3. Perform Pairwise Comparisons ---\n",
        "comparisons = [\n",
        "    ('Advanced', 'Intermediate'),\n",
        "    ('Intermediate', 'Foundation'),\n",
        "    ('Advanced', 'Foundation')\n",
        "]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for label1, label2 in comparisons:\n",
        "    # Get the Aptitude Scores for the two groups\n",
        "    g1 = df[df['course_level'] == label1]['aptitude_score']\n",
        "    g2 = df[df['course_level'] == label2]['aptitude_score']\n",
        "\n",
        "    # Calculate Stats\n",
        "    diff = g1.mean() - g2.mean()\n",
        "    t_stat, p_val = stats.ttest_ind(g1, g2)\n",
        "    d_val = calculate_cohens_d(g1, g2)\n",
        "\n",
        "    # Format Row\n",
        "    rows.append({\n",
        "        'Comparison': f\"{label1} vs {label2}\",\n",
        "        'Difference': f\"{diff:.1f} points\",\n",
        "        'p-value': \"<0.001\" if p_val < 0.001 else f\"{p_val:.3f}\",\n",
        "        'Effect Size': f\"{d_val:.2f}\",\n",
        "        'Interpretation': interpret_effect(d_val)\n",
        "    })\n",
        "\n",
        "# --- 4. Display Table ---\n",
        "results = pd.DataFrame(rows)\n",
        "\n",
        "# Adjust display settings to ensure full table visibility\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(\"6.3.2  Comparing Specific Pairs of Levels\\n\")\n",
        "print(\"Table 5: Pairwise Aptitude Comparisons\")\n",
        "print(results.to_string(index=False))"
      ],
      "metadata": {
        "id": "TOxKtjYsaMVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7: Correlation Analysis"
      ],
      "metadata": {
        "id": "o5VNzQa0ZdYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 8: Effect Sizes (Cohen's d)"
      ],
      "metadata": {
        "id": "qY5rJ9oGZgJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 9: Comprehensive Visualizations"
      ],
      "metadata": {
        "id": "6QqmH4_NZkh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Setup Figure ---\n",
        "sns.set_style(\"darkgrid\")\n",
        "# Create a 3x3 Grid (3 Rows, 3 Columns)\n",
        "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
        "\n",
        "# Increase vertical spacing so titles don't overlap\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "# ==========================================\n",
        "# ROW 1: Boxplots & Performance Violin\n",
        "# ==========================================\n",
        "\n",
        "# 1.1 Performance Boxplot (Left)\n",
        "sns.boxplot(\n",
        "    data=df, x='course_level', y='performance_score',\n",
        "    order=['Advanced', 'Foundation', 'Intermediate'],\n",
        "    boxprops=dict(facecolor=(0,0,0,0)), # Transparent\n",
        "    width=0.5, linewidth=1.2, fliersize=6,\n",
        "    ax=axes[0, 0]\n",
        ")\n",
        "axes[0, 0].set_title('Performance Score Distribution by Course Level', fontsize=14)\n",
        "axes[0, 0].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "# 1.2 Aptitude Boxplot (Middle)\n",
        "sns.boxplot(\n",
        "    data=df, x='course_level', y='aptitude_score',\n",
        "    order=['Advanced', 'Foundation', 'Intermediate'],\n",
        "    boxprops=dict(facecolor=(0,0,0,0)), # Transparent\n",
        "    width=0.5, linewidth=1.2, fliersize=6,\n",
        "    ax=axes[0, 1]\n",
        ")\n",
        "axes[0, 1].set_title('Aptitude Score Distribution by Course Level', fontsize=14)\n",
        "axes[0, 1].tick_params(axis='both', which='major', labelsize=11)\n",
        "axes[0, 1].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "# 1.3 Performance Violin Plot (Right)\n",
        "sns.violinplot(\n",
        "    data=df, x='course_level', y='performance_score',\n",
        "    order=['Advanced', 'Intermediate', 'Foundation'],\n",
        "    color='#F6848F', inner='box', linewidth=1.2,\n",
        "    ax=axes[0, 2]\n",
        ")\n",
        "axes[0, 2].set_title('Performance Score Distribution (Violin Plot)', fontsize=14)\n",
        "axes[0, 2].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# ROW 2: Aptitude Violin & Bar Charts\n",
        "# ==========================================\n",
        "\n",
        "# 2.1 Aptitude Violin Plot (Left)\n",
        "sns.violinplot(\n",
        "    data=df, x='course_level', y='aptitude_score',\n",
        "    order=['Advanced', 'Intermediate', 'Foundation'],\n",
        "    color='#F6848F', inner='box', linewidth=1.2,\n",
        "    ax=axes[1, 0]\n",
        ")\n",
        "axes[1, 0].set_title('Aptitude Distribution (Violin Plot)', fontsize=14)\n",
        "axes[1, 0].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "# 2.2 Mean Performance Bar Plot (Middle)\n",
        "sns.barplot(\n",
        "    data=df, x='course_level', y='performance_score',\n",
        "    order=['Advanced', 'Foundation', 'Intermediate'],\n",
        "    errorbar='sd', capsize=0.1, width=0.5,\n",
        "    hue='course_level', legend=False,\n",
        "    err_kws={'color': 'black', 'linewidth': 1.5},\n",
        "    ax=axes[1, 1]\n",
        ")\n",
        "axes[1, 1].set_title('Mean Performance Score by Level (with SD)', fontsize=14)\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "axes[1, 1].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "# 2.3 Mean Aptitude Bar Plot (Right)\n",
        "sns.barplot(\n",
        "    data=df, x='course_level', y='aptitude_score',\n",
        "    order=['Advanced', 'Foundation', 'Intermediate'],\n",
        "    errorbar='sd', capsize=0.1, width=0.5,\n",
        "    hue='course_level', legend=False,\n",
        "    err_kws={'color': 'black', 'linewidth': 1.5},\n",
        "    ax=axes[1, 2]\n",
        ")\n",
        "axes[1, 2].set_title('Mean Aptitude Score by Level (with SD)', fontsize=14)\n",
        "axes[1, 2].tick_params(axis='x', rotation=45)\n",
        "axes[1, 2].grid(axis='x', color='white', linestyle='-', linewidth=1.5)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# ROW 3: Correlation & Histograms\n",
        "# ==========================================\n",
        "\n",
        "# 3.1 Scatter Plot with Regression (Left)\n",
        "# Calculate Correlation\n",
        "import scipy.stats as sps # Local import and alias to avoid name collision with 'stats' DataFrame variable\n",
        "r, p = sps.pearsonr(df['performance_score'], df['aptitude_score'])\n",
        "\n",
        "sns.scatterplot(\n",
        "    data=df, x='performance_score', y='aptitude_score',\n",
        "    hue='course_level', s=80, alpha=0.7, palette='tab10',\n",
        "    ax=axes[2, 0]\n",
        ")\n",
        "sns.regplot(\n",
        "    data=df, x='performance_score', y='aptitude_score',\n",
        "    scatter=False, ci=None, line_kws={\"color\": \"red\", \"ls\": \"--\", \"linewidth\": 2.5},\n",
        "    ax=axes[2, 0]\n",
        ")\n",
        "axes[2, 0].set_title(f'Performance vs Aptitude Score (r = {r:.3f})', fontsize=14)\n",
        "axes[2, 0].legend(loc='upper left', frameon=False)\n",
        "\n",
        "# Custom Colors for Histograms\n",
        "colors = {'Advanced': '#F49AC2', 'Intermediate': '#C4B083', 'Foundation': '#93C47D'}\n",
        "\n",
        "# 3.2 Performance Histogram (Middle)\n",
        "for level, color in colors.items():\n",
        "    sns.histplot(\n",
        "        data=df[df['course_level'] == level], x='performance_score',\n",
        "        bins=15, alpha=0.6, color=color, label=level, edgecolor=None, linewidth=0,\n",
        "        ax=axes[2, 1]\n",
        "    )\n",
        "axes[2, 1].set_title('Performance Score Histogram by Level', fontsize=14)\n",
        "axes[2, 1].legend(labels=['Advanced', 'Intermediate', 'Foundation'])\n",
        "\n",
        "# 3.3 Aptitude Histogram (Right)\n",
        "for level, color in colors.items():\n",
        "    sns.histplot(\n",
        "        data=df[df['course_level'] == level], x='aptitude_score',\n",
        "        bins=15, alpha=0.6, color=color, label=level, edgecolor=None, linewidth=0,\n",
        "        ax=axes[2, 2]\n",
        "    )\n",
        "axes[2, 2].set_title('Aptitude Score Histogram by Level', fontsize=14)\n",
        "axes[2, 2].legend(labels=['Advanced', 'Intermediate', 'Foundation'])\n",
        "\n",
        "# --- Final Layout ---\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0eKszIUbOE_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 10: Summary and Conclusions"
      ],
      "metadata": {
        "id": "j1J3o-pOZo5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Calculate Correlation Statistics ---\n",
        "# Pearson correlation returns the coefficient (r) and the p-value\n",
        "r, p_value = stats.pearsonr(df['aptitude_score'], df['performance_score'])\n",
        "\n",
        "# Calculate Shared Variance (Coefficient of Determination, r-squared)\n",
        "# This represents the percentage of variation in one variable explained by the other\n",
        "shared_variance = r ** 2\n",
        "\n",
        "# --- 3. Build the Table Data ---\n",
        "# We manually construct the rows to match the specific format of your image\n",
        "data = [\n",
        "    {\n",
        "        'Relationship': 'Aptitude <-> Performance',\n",
        "        'Correlation (r)': f\"{r:.3f}\",\n",
        "        'Interpretation': 'Very Strong Positive' # Interpretation based on r > 0.8\n",
        "    },\n",
        "    {\n",
        "        'Relationship': 'Statistical Significance',\n",
        "        'Correlation (r)': 'p < 0.001' if p_value < 0.001 else f\"{p_value:.4f}\",\n",
        "        'Interpretation': 'Extremely Confident' # Interpretation based on p < 0.001\n",
        "    },\n",
        "    {\n",
        "        'Relationship': 'Shared Variance',\n",
        "        'Correlation (r)': f\"{shared_variance*100:.1f}%\",\n",
        "        'Interpretation': 'High Predictability' # Interpretation based on high r-squared\n",
        "    }\n",
        "]\n",
        "\n",
        "# --- 4. Create and Display Table ---\n",
        "results_df = pd.DataFrame(data)\n",
        "\n",
        "# Adjust display settings for clean output\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "print(\"7.2  Overall Correlation Results\\n\")\n",
        "print(\"Table 6: Correlation Between Aptitude and Performance\")\n",
        "print(results_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "EluevrSpcbpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Define Interpretations (Text from your image) ---\n",
        "# Since the \"What This Means\" column is qualitative text, we map it to the levels.\n",
        "descriptions = {\n",
        "    'Advanced': 'Even among advanced students, aptitude predicts performance',\n",
        "    'Intermediate': 'Clear aptitude-performance link in the middle range',\n",
        "    'Foundation': 'Weaker but still meaningful relationship'\n",
        "}\n",
        "\n",
        "# --- 3. Calculate Correlations by Group ---\n",
        "rows = []\n",
        "# We force the specific order: Advanced -> Intermediate -> Foundation\n",
        "order = ['Advanced', 'Intermediate', 'Foundation']\n",
        "\n",
        "for level in order:\n",
        "    # Get data for this specific level\n",
        "    subset = df[df['course_level'] == level]\n",
        "\n",
        "    # Calculate Pearson Correlation\n",
        "    r, _ = stats.pearsonr(subset['aptitude_score'], subset['performance_score'])\n",
        "\n",
        "    # Determine Strength Label dynamically based on r value\n",
        "    if r > 0.7:\n",
        "        strength = \"Strong\"\n",
        "    elif r > 0.4:\n",
        "        strength = \"Moderate\"\n",
        "    else:\n",
        "        strength = \"Weak-Moderate\"\n",
        "\n",
        "    # Append to list\n",
        "    rows.append({\n",
        "        'Level': level,\n",
        "        'Correlation': f\"{r:.3f}\",\n",
        "        'Strength': strength,\n",
        "        'What This Means': descriptions[level]\n",
        "    })\n",
        "\n",
        "# --- 4. Create and Format Table ---\n",
        "results_df = pd.DataFrame(rows)\n",
        "\n",
        "# Adjust pandas settings to ensure the long text sentences don't get cut off\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "print(\"7.3  Correlation Within Each Course Level\\n\")\n",
        "print(\"Table 7: Correlations Within Each Course Level\")\n",
        "print(results_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "GC96JOhIdeOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "df = pd.read_csv('student_combined_data.csv')\n",
        "\n",
        "# --- 2. Calculate Correlation Matrix ---\n",
        "# Select only the two columns we want to compare\n",
        "corr_matrix = df[['performance_score', 'aptitude_score']].corr()\n",
        "\n",
        "# --- 3. Setup Styling ---\n",
        "# Use white background so the white lines between heatmap squares are visible\n",
        "sns.set_style(\"white\")\n",
        "plt.figure(figsize=(7, 6))\n",
        "\n",
        "# --- 4. Draw the Heatmap ---\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,          # Show the numbers (0.89, 1) in the squares\n",
        "    cmap='RdYlGn',       # Red-Yellow-Green colormap (matches the red in your image)\n",
        "    center=0,            # centers the colormap\n",
        "    vmin=0.88, vmax=1,   # Limits the color range to make the red intense (since correlation is high)\n",
        "    linewidths=2,        # Width of the white lines between squares\n",
        "    linecolor='white',   # Color of the lines\n",
        "    square=True,         # Forces squares to be perfect squares\n",
        "    cbar_kws={\"shrink\": 0.8} # Slightly shrinks the color bar on the right\n",
        ")\n",
        "\n",
        "# --- 5. Customization ---\n",
        "plt.title('Correlation Heatmap: Performance vs Aptitude Score', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5jOKk-QWeNKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dlU_YhIcefdr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}